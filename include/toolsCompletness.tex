%\chapter{Tools Completeness}
%\label{ch:tools_completness}

%\section{Introduction}
%In this chapter it will be examined how complete \ac{PAM}, TAA and \ac{OPS} are in measuring agility compared to one another.
%
%\subsection{Research Question}
%\begin{itemize}
%	\item How much complete are the tools in measuring agility?
%\end{itemize}
%
%\section{Team Agility Assessment Areas}
%Team Agility Assessment (\ac{TAA}) does not claim that it covers specific agile practices, but rather areas important for a team. It focuses on product ownership for Scrum teams but also on the release and iteration planning and tracking. The team factor plays a great role, as well as the development practices and the working environment. Automated testing is important here as well. Finally, it is worth mentioning that it is the only tool focusing so much on the release planning. In Table~\ref{table:taa_practices} one can see \ac{TAA}'s areas.
%
%\begin{table}
%  \begin{tabular}{| p{5cm} p{5cm} |}
%    \hline
%    \multicolumn{2}{|c|}{\textbf{\ac{TAA} Areas}}  \\ \hline
%     \begin{itemize} \item Product Ownership \item Release Planning and Tracking \item Iteration Planning and Tracking \end{itemize} &
%     \begin{itemize}  \item Team \item Testing Practices \item Development Practices / Infrastructure \end{itemize}  \\ \hline
%  \end{tabular}
%  \captionof{table}{Areas covered by \ac{TAA}}
%  \label{table:taa_practices}
%\end{table}
%
%\section[\ac{PAM} Practices]{Perceptive Agile Measurement Practices}
%The Perceptive Agile Measurement (\ac{PAM}) tool focuses on the iterations during software development but also on the stand-up meetings among the team members, their collocation and the retrospectives they have. The customers access and their acceptance criteria have a high significance as well. Finally, the continuous integration and the automated unit testing are considered crucial in order to be agile. In Table~\ref{table:pam_practices} one can see \ac{PAM}'s practices.
%
%\begin{table} [H]
%  \begin{tabular}{| p{6cm} p{6cm} |}
%    \hline
%    \multicolumn{2}{|c|}{\textbf{\ac{PAM} Practices}}  \\ \hline
%    	\begin{itemize} \item Iteration Planning \item Iterative Development \item Continuous Integration and Testing \item Co-Location \end{itemize} &
%     \begin{itemize} \item Stand-up Meetings \item Customer Access \item Customer Acceptance Tests \item Retrospectives \end{itemize}  \\ \hline
%  \end{tabular}
%  \captionof{table}{Agile practices covered by \ac{PAM}}
%  \label{table:pam_practices}
%\end{table}
%
%\section{Objectives, Principles, Strategies Practices}
%Objectives, Principles, Strategies (\ac{OPS}) Framework is the successor of the Objectives, Principles, Practices (\ac{OPP}) Framework \cite{opp}. \ac{OPP} identified 27 practices as implementations of the principles which later on were transformed into 17 strategies. In Table~\ref{table:opp_practices} one can see \ac{OPP}'s practices. 
%
%\begin{table}
%\begin{tabular}{| p{7.5cm}  p{7.5cm} |}
%	\hline
%	\multicolumn{2}{|c|}{\textbf{\ac{OPP} Practices}}  \\ \hline
%     	\begin{itemize}
%     		\item Iterative and Incremental Development 
%     		\item Continuous Feedback 
%     		\item Evolutionary Requirements 
%     		\item Smaller and Frequent Product Releases 
%     		\item Customer/User Acceptance Testing 
%     		\item Frequent Face-to-Face Communication
%     		\item Refactoring 
%     		\item Automated Test Builds
%     		\item Software Configuration Management 
%     		\item Test Driven Development
%     		\item Iteration Progress Tracking and Reporting 
%     		\item Code Ownership 
%     		\item Retrospectives Meetings 
%     		\item Just-in-Time Refinement of Features /Stories/Tasks 
%     	\end{itemize} 
%     	& \begin{itemize}
%     	 	\item Appropriate Distribution of Expertise
%  			\item Self-Organizing Teams
%     		\item Client-Driven Iterations 
%     		\item Product Backlog 
%     		\item Agile Project Estimation 
%     		\item Adherence to Coding Standards 
%     		\item Physical Setup Reflecting Agile Philosophy
%     		\item Daily Progress Tracking Meetings 
%     		\item Minimal or Just Enough Documentation 
%     		\item Minimal Big Requirements Up Front and Big Design Up Front 
%     		\item Collocated Customers
%     		\item Constant Velocity 
%     		\item Pair Programming  
% 		\end{itemize} 
%     \\ \hline
%\end{tabular}
%\captionof{table}{Agile practices covered by \ac{OPP}}
%\label{table:opp_practices}
%\end{table}
%
%\section[Tool Practices]{Practices Covered Between The Tools}
%
%As it can be clearly seen in Tables~\ref{table:opp_practices}, \ref{table:pam_practices} and \ref{table:taa_practices}, the \ac{OPP}, and as a consequence the \ac{OPS}, covers more agile practices than the other tools. \\
%
%In the next pages a mapping between \ac{OPP} and \ac{PAM} (see Table~\ref{table:opp_pam_practices}) and \ac{OPP} and \ac{TAA} (see Table~\ref{table:opp_taa_practices}) follows. \\
%
%Some of the \ac{OPP} practices though have abstracted to \ac{OPS} strategies in order to avoid repetition of the questions' mapping and to better reflect the \ac{OPS} Framework. The \ac{OPP} practices \begin{inparaenum} [a\upshape)]
%	\item \textit{Frequent Face-to-Face Communication},
%	\item \textit{Physical Setup Reflecting Agile Philosophy}, and
%	\item \textit{Collocated Customers}
%\end{inparaenum} have been abstracted to the \ac{OPS} strategy \textit{High-Bandwidth Communication}  \cite[p. 57]{sventha_dissertation}. In the same way, the \ac{OPP} \textit{Automated test builds} practice has been abstracted to the \ac{OPS} strategy \textit{Continuous Integration} \cite[p. 57]{sventha_dissertation}. \\
%
%The connection between the practices and strategies is done based on the questions of each tool. The aforementioned connections are depicted with colours. When a practice has more than one colour, it is because it covers more practices from the other tool (The colours and symbols among Tables~\ref{table:opp_pam_practices}, ~\ref{table:opp_taa_practices} are randomly selected and do not imply any connection between the two tables). \\
%
%\begin{table}
%\begin{tabular}{| p{6.8cm} | p{8cm} |}
%	\hline
%	\textbf{\ac{PAM}} & \textbf{\ac{OPP}/\ac{OPS}}  \\ \hline
%		 \begin{itemize}[leftmargin=*, label=]
% 			\item {\color{RoyalBlue1}Iteration Planning} \FourStar
% 			\item {\color{DarkMagenta}Iterative Development} \JackStarBold
% 			\item {\color{DarkOrange1}Continuous Integration and Testing} \AsteriskRoundedEnds 
% 			\item {\color{DeepPink1}Co-Location} \Asterisk 
% 			\item {\color{green4}Stand-up Meetings} \EightStar
% 			\item {\color{DarkBlue}Customer Access} \JackStar
% 			\item {\color{red2}Customer Acceptance Tests} \AsteriskThin
% 			\item {\color{DarkRed}Retrospectives} \CrossMaltese
% 		\end{itemize}
% 		&
%     	\begin{itemize}[leftmargin=*, label=]
%     		\item {\color{RoyalBlue1}Iteration Progress Tracking and Reporting} \FourStar
%     		\item {\color{RoyalBlue1}Iterative} {\color{DarkMagenta}and Incremental  Development} \FourStar ~\JackStarBold
%     		\item {\color{DarkOrange1}Continuous Integration} \AsteriskRoundedEnds
%     		\item {\color{DarkOrange1}Software Configuration Management} \AsteriskRoundedEnds
%     		\item {\color{DarkOrange1}Test Driven} {\color{red2}Development} \AsteriskRoundedEnds ~\AsteriskThin 
%     		\item {\color{DarkBlue}High-Bandwidth} {\color{DeepPink1}Communication} \JackStar ~\Asterisk 
%     		\item {\color{green4}Daily Progress Tracking Meetings} \EightStar
%     		\item {\color{DarkBlue}Client-Driven} {\color{RoyalBlue1}Iterations} \JackStar ~\FourStar
%     		\item {\color{red2}Evolutionary Requirements} \AsteriskThin
%     		\item {\color{red2}Customer/User Acceptance Testing} \AsteriskThin
%     		\item {\color{DarkRed}Retrospectives Meetings} \CrossMaltese
%     		\item {\color{RoyalBlue1}Self-Organizing Teams} \FourStar
% 		\end{itemize} 
%     \\ \hline
%\end{tabular}
%\caption{Relation of \ac{OPP}/\ac{OPS} and \ac{PAM} practices}
%\label{table:opp_pam_practices}
%\end{table}
%
%\begin{table}
%\begin{tabular}{| p{7cm} | p{7.8cm} |}
%	\hline
%	\textbf{\ac{TAA}} & \textbf{\ac{OPP}/\ac{OPS}}  \\ \hline
%		\begin{itemize}[leftmargin=*, label=] 
%     		\item {\color{DeepPink1}Product Ownership} \Asterisk 
%     		\item {\color{green4}Release Planning and Tracking} \EightStar
%     		\item {\color{RoyalBlue1}Iteration Planning and Tracking} \FourStar
%     		\item {\color{DarkRed}Team} \CrossMaltese
%     		\item {\color{DarkOrange1}Testing Practices} \AsteriskRoundedEnds
%     		\item {\color{DarkMagenta}Development Practices/Infrastructure} \JackStar	
% 		\end{itemize} 
%		&	
%     	\begin{itemize}[leftmargin=*, label=]
%     		\item {\color{DeepPink1} Iterative and Incremental Development} \Asterisk 
%     	    \item {\color{DeepPink1}Product Backlog} \Asterisk 
%     		\item {\color{green4}Smaller and Frequent Product Releases} \EightStar
%     		\item {\color{RoyalBlue1}Customer/User {\color{green4}Acceptance Testing}} \FourStar ~\EightStar
%     		\item {\color{RoyalBlue1}Constant Velocity} \FourStar	
%     		\item {\color{RoyalBlue1}Iteration Progress Tracking and Reporting} \FourStar
%     		\item {\color{DarkRed}Self-} {\color{green4}Orga}{\color{RoyalBlue1}nizing} {\color{DarkMagenta}Teams} \CrossMaltese ~\EightStar ~\FourStar ~\JackStar 
%     		\item {\color{DarkRed}Appropriate Distribution of Expertise} \CrossMaltese
%     		\item {\color{DarkRed}High-Bandwidth Communication} \CrossMaltese 
%     		\item {\color{DarkRed}Daily Progress Tracking Meetings} \CrossMaltese
%     		\item {\color{DarkRed}Retro}{\color{RoyalBlue1}spectives} {\color{green4}Meetings}  \CrossMaltese ~\FourStar ~\EightStar 
%     		\item {\color{DarkOrange1}Test Driven Development} \AsteriskRoundedEnds
%     		\item {\color{DarkMagenta}Refactoring} \JackStar
%     		\item {\color{DarkMagenta}Software Configuration Management} \JackStar
%     		\item {\color{DarkMagenta}Adherence to Coding Standards} \JackStar
%     		\item {\color{DarkMagenta}Pair Programming} \JackStar
%     		\item {\color{DarkMagenta}Continuous} {\color{DarkOrange1}Integration} \JackStar ~\AsteriskRoundedEnds
%     	\end{itemize} 
%     \\ \hline
%\end{tabular}
%\caption{Relation of \ac{OPP}/\ac{OPS} and \ac{TAA} practices/areas}
%\label{table:opp_taa_practices}
%\end{table}
%
%
%\section[\ac{PAM} and \ac{TAA} Mapping]{Mapping of questions from the \ac{PAM} and \ac{TAA} tools}
%\label{mapping}
%
%The \ac{PAM} has divided its questions based on agile practices, while on the other hand, the \ac{TAA} has divided them based on areas considered important. In the next pages, there is a mapping between the questions used from the \ac{PAM} and \ac{TAA} tools with the practices from \ac{OPP} and the strategies from \ac{OPS}. As one can see from the tables above, while all practices/areas from \ac{PAM} and \ac{TAA} are mapped to \ac{OPP} and \ac{OPS}, not all of their questions are under \ac{OPP} practices or \ac{OPS} strategies. This can be explained due to the different perception/angle, of the creators of the tools, of what is important for an organization to be agile.
%
%The questions among the tools will be matched based on whether they are covered directly, relevantly, or not at all. Direct match will be considered the one where a question from a tool is the same or almost similar with one from \ac{OPS}. Relevant match will be considered the one where a question of a tool does not exist in \ac{OPS}, but its practice does exist in \ac{OPS}. Non-relevant match will be considered the one where a question cannot be matched at all in \ac{OPS}. 
%
%The detailed mapping of the tools can be viewed in Appendix~\ref{ch:mapping}.


%\section{Analysis}
%\label{tools_completeness_analysis}
%As far as RQ \#2 is concerned, by viewing Tables~\ref{table:opp_pam_practices} ~\ref{table:opp_taa_practices} and Appendix~\ref{ch:mapping}, one can clearly distinguish that \ac{OPP} and consequently \ac{OPS} is more complete than the others in measuring agility, covering all the areas of the \ac{PAM} and \ac{TAA} tools. Furthermore, as it can be seen in Table~\ref{table:questions_coverage}, the \ac{OPS} covers a high percent of questions from both tools directly and relevantly. The \ac{TAA} has a respective percent of non-relevant matches mostly due to \textit{Product Ownership} perspectives, which is not covered to such an extent from \ac{OPS}. This can be explained by the fact that \ac{OPS} covers basic  methodologies for developing software such as XP, FDD, Crystal, Lean \cite[p. 44]{sventha_dissertation}, whereas \textit{Product Ownership} refers explicitly to Scrum which is a method for managing product development \cite{koch2005agile}. 

%On the other hand, \ac{OPS} considers the release cycle as smaller iteration cycles \cite[p. 13]{sventha_dissertation}, which as a consequence makes the framework set the focus on the iterations, rather than the releases. As a result the  is only covered to a small extent.

%\begin{table} [H]
%	\begin{tabular}{{| p{4cm} | p{4cm} | p{4cm} |}}
%		\hline
%		\multicolumn{3}{|c|}{\textbf{Questions Coverage}}  \\ \hline
%		\textbf{Match}  & \textbf{\ac{PAM}} & \textbf{\ac{TAA}}  \\ \hline		
%		Direct Match & 17/48 (35.4\%) & 25/68 (36.7\%) \\ \hline
%		Relevant Match & 31/48 (64.5\%) & 33/68 (48.5\%) \\ \hline
%		Non Relevant & 0/48 (0\%) & 10/68 (14.7\%) \\ \hline
%	\end{tabular}
%\caption{Questions Coverage from \ac{OPS}}
%\label{table:questions_coverage}
%\end{table}


\chapter{Measuring Agility More Completely}
\label{ch:enhancing_ops}

\lettrine[lines=2, loversize=-0.1, lraise=0.1]{T}{his} chapter makes an effort to combine \ac{PAM}, \ac{TAA} and \ac{OPS} in a more enhanced one, based on \ac{OPS}'s structure. 

\bigskip

\textbf{Chapter not finished}

\section{Introduction}
As it was discussed in Section~\ref{subsec:tools_completeness_analysis}, \ac{OPP} and subsequently \ac{OPS} covers all the practices and areas of both \ac{PAM} and \ac{TAA}. In this chapter, there will be an effort to combine the tools in a way to provide a more complete tool in measuring agility.

\subsection{Research Question}
\begin{enumerate}
	\setcounter{enumi}{\thetmpc} % counter continues for the RQs
	\item Can the tools be combined in a way so that they can produce a more complete approach in measuring agility?
\end{enumerate}

\section{\ac{OPS} Enhancement}
The combination of the tools took place based on the analysis performed in Section~\ref{subsec:tools_completeness_analysis}. Since \ac{OPS} is more complete, it was selected to remain as it is and be enhanced with the questions from \ac{PAM} and \ac{TAA} which have been transformed to match the style of \ac{OPS}.

Although the case study performed in Section~\ref{sec:method} used only the ``Effectiveness" survey from \ac{OPS}, it was selected to enhance the ``Capability" part as well, since some of the \ac{PAM} and \ac{TAA} questions fit there more.

\subsection{Questions Excluded}
The questions excluded belong only to \ac{TAA}. Most of them were referring to product ownership and were needless, since \ac{OPS} focuses on measuring teams practising agile development methods like eXtreme Programming, Crystal, First Driven Development and not agile project management methods like Scrum. The other question excluded was about iteration defects being fixed within the iteration. Although a software without defects is always welcome, trying to mitigate all of them throws away some of the team's agility, since the release could be delayed. Defects should be fixed with a delay in the software's release only if they are a stopper for the business of the customer.

\subsection{Questions Added}
The questions which already existed in \ac{OPS} remained as they were, apart from the question ``To what extent are the code bases not shared" which was changed based on the reasons described in Section~\ref{subsec:opposite_questions}. The questions which were added, were formulated and positioned under the appropriate \ac{OPS} indicator. When an indicator did not cover the questions added, a new one was created. The \ac{OPS} questions follow the pattern of starting a question with the phrase ``To what extent \dots ". The same pattern was used in the additional questions. In Table~\ref{table:summary_questions_added}, one can see the number of indicators and questions added. 

\begin{table} [H]
	\caption{Summary of Indicators and Questions Added}
	\label{table:summary_questions_added}
	\begin{tabular}{| c | c | c |} \hline
		 & \textbf{Indicators Introduced} & \textbf{Questions Introduced} \\ \hline
		 \textbf{Capability} & 3 & 7 \\ \hline
		 \textbf{Effectiveness} & 9 & 46 \\ \hline
	\end{tabular}
\end{table}

In total, 11 indicators and 53 questions were introduced. The questions did not exist in \ac{OPS} and they cover a variety of aspects which were considered important by the creators of \ac{PAM} and \ac{TAA}. The \ac{OPS} now has in total 46 indicators and 77 questions for ``Capability" and 45 indicators and 126 questions for ``Effectiveness". Although \ac{OPS} supports 17 strategies, and ``Velocity" is one of them, it was not used in the surveys. On the contrary, questions in \ac{PAM} and \ac{TAA} supported this strategy and thus it was added in both ``Capability" and ``Effectiveness". In Table~\ref{table:numbers_enhanced_ops}, one can see in more details the numbers of indicators and questions for each strategy. In Appendix~\ref{ch:ops_pam_taa}, one can see the enhanced \ac{OPS}. Below is the list of symbols that describe the type of addition.

\begin{itemize}
	\item strategy addition - \TwelweStar
	\item indicator addition - \FiveStarOutline
	\item question addition - \FiveStar
\end{itemize}

\begin{table}
	\caption{Numbers of indicators and questions in the enhanced \ac{OPS}}
	\label{table:numbers_enhanced_ops}
	\begin{tabular}{| p{.33\textwidth} | p{.13\textwidth} | p{.13\textwidth} | p{.13\textwidth} | p{.13\textwidth} |} \hline
	\multirow{2}{*}{\textbf{Strategy}} & \multicolumn{2}{c|}{\textbf{Capability}} & \multicolumn{2}{c|}{\textbf{Effectiveness}} \\ \hhline{~----}
	& \textbf{No. of Indicators}  & \textbf{No. of Questions} & \textbf{No. of Indicators} & \textbf{No. of Questions} \\ \hline
	Iterative Progression & 3 & 4 & 4 & 18 \\ \hline
	Incremental Development & 3 & 4 & 2 & 8 \\ \hline
	Short Delivery Cycles & 1 & 1 & 3 & 4 \\ \hline
	Evolutionary Requirements & 3 & 4 & 3 & 5 \\ \hline
	Continuous Feedback & 2 & 2 & 3 & 5 \\ \hline
	Distribution of Expertise & 1 & 3 & 1 & 6 \\ \hline
	Test-first development & 3 & 5 & 3 & 5 \\ \hline
	Refactoring & 3 & 9 & 2 & 7 \\ \hline
	Adherence to standards & 5 & 6 & 2 & 3 \\ \hline
	Continuous Integration & 4 & 10 & 4 & 15 \\ \hline
	Configuration Management & 2 & 6 & 1 & 1 \\ \hline
	Minimal Documentation & 3 & 3 & 1 & 4 \\ \hline
	High bandwidth Communication & 4 & 9 & 5 & 21 \\ \hline
	Self-Managing Teams & 5 & 6 & 4 & 9 \\ \hline
	Client-driven Iterations & 1 & 2 & 3 & 4 \\ \hline
	Retrospection & 2 & 2 & 3 & 10 \\ \hline
	Velocity & 1 & 1 & 1 & 1 \\ \hline
	\textbf{Total} & \textbf{46} & \textbf{77} & \textbf{45} & \textbf{126}  \\ \hline
	\end{tabular}
\end{table}





%Mention in which practices you added questions or what type of questions were added. Mention about velocity addition

%Answer to the research question


Even though \ac{PAM}, \ac{TAA} and \ac{OPS} have been validated individually, still their combination needs to be validated too, in a future work on the topic. The enhanced surveys of ``Capability" and ``Effectiveness" could be given to software development teams to answer them and check its scores in comparison to answering each one of them.  

\section{Chapter Summary}
In this chapter there was an effort to enhance \ac{OPS} with questions from \ac{PAM} and \ac{TAA}. The questions added cover \ac{OPS}'s weaknesses. After the changes, \ac{OPS} has in total 46 indicators and 77 questions for ``Capability" and 45 indicators and 126 questions for ``Effectiveness".


\chapter{Discussion}
\label{ch:discussion}
%This chapter tried to check the correlations between \textit{Perceptive Agile Measurement}, \textit{Team Agility Assessment} and \textit{Objectives Practices and Strategies} tools. One would expect that their results would be similar, since their creators claim they can measure the agility of software development teams. Unfortunately, as it was seen in the analysis, the correlations among them were only few and most of them were very low (check subsection ~\ref{subsec:correlation_analysis}).



%Team size
%http://www.jamesshore.com/Agile-Book/the_xp_team.html
%http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6681108&matchBoolean%3Dtrue%26searchField%3DSearch_All%26queryText%3D%28%28Agile%29+AND+team+size%29
%http://www.academia.edu/4893042/Team_size_in_agile_development_-_A_limiting_factor




%\begin{itemize}
%	\item Product owner defines acceptance criteria for stories 
%	\item Product owner and stakeholders participate at iteration and release planning 
%	\item Product owner and stakeholders participate at iteration and release review 
%	\item Product owner collaboration with team is continuous
%	\item Team completes and product owner accepts the release by the release date
%	\item Work is not added by the product owner during the iteration
%	\item Team completes and product owner accepts the iteration
%\end{itemize}