%discussion about the agility of the teams based on how they manage things
%discussion about the tools being close to the agile manifesto
%Dave Thomas argues about selling agility while we move away from agility (ruby grooves podcast - lister after 20th minute)
%http://msdn.microsoft.com/en-us/library/dd997578.aspx
%describe why it is difficult to measure. Companies adjust the methods to their needs. This is good, but the custom solutions are not measurable always Search for difficulties in agile or transitioning to agile. Difficulties in transition make people not adopting well the method and the practices.

\chapter{Discussion}
\label{ch:discussion}
%This chapter tried to check the correlations between \textit{Perceptive Agile Measurement}, \textit{Team Agility Assessment} and \textit{Objectives Practices and Strategies} tools. One would expect that their results would be similar, since their creators claim they can measure the agility of software development teams. Unfortunately, as it was seen in the analysis, the correlations among them were only few and most of them were very low (check subsection ~\ref{subsec:correlation_analysis}).

%\section{Unkwown}
%
%The agile philosophy became widely known to the Software Engineering community through the agile manifesto \cite{beck2001agile} which was also listed in the Introduction of this document. Along with the four pillars of the manifesto lie 12 principles \cite{agile_principles} which try to provide to people a better understanding of what agile means. All of them combined, consist the essence of what it is to be Agile \cite{agile_alliance}.
%
%\begin{itemize}
%	\item Our highest priority is to satisfy the customer through early and continuous delivery of valuable software.
%    \item Welcome changing requirements, even late in development. Agile processes harness change for the customer's competitive advantage.
%    \item Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale.
%    \item Business people and developers must work together daily throughout the project.
%    \item Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done.
%    \item The most efficient and effective method of conveying information to and within a development team is face-to-face conversation.
%    \item Working software is the primary measure of progress.
%    \item Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely.
%    \item Continuous attention to technical excellence and good design enhances agility.
%    \item Simplicity--the art of maximizing the amount of work not done--is essential.
%    \item The best architectures, requirements, and designs emerge from self-organizing teams.
%    \item At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behaviour accordingly.
%\end{itemize}
%
%Considering that the agile manifesto and its principles are the meaning of agility, then how well do the tools measuring agility succeed in doing so based on them?


\section{Threats to Validity}

\subsection{Construct Validity}
Construct validity mainly deals with obtaining the right method for the concept under study \cite{Wohlin}.

Structural?
Convergent validity?

%Here, mono-method bias was considered as a potential risk, and we tried
%to minimize by conducting pilot survey and interviews. The tools used to deploy our questionnaire guarantees subjects anonymity, thus helped us to avoid evaluation apprehension
%
%To assure a common understanding of the concepts used in data collection instruments, each study participant went through a printed survey form together with the researchers, where the latter explained every section in detail and the former was able to ask clarifying questions
%
%To alleviate the surveyâ€™s potential instrumentation flaws it was designed with the results of previous studies by Sekitoleko et al. [62] and Borjesson [9] and feedback of trial participants as an input.
%
%The evaluation apprehension threat [77], stemming from people being afraid of eval-
%uation by their nature, was mitigated by guaranteeing anonymity to every study partic-
%ipant within the company and in any publications of the study.
%
%Hypothesis Guessing
%
%http://www.socialresearchmethods.net/kb/constval.php


\subsection{Internal Validity}
Internal validity deals with the issues that may affect the casual relationship between treatment and results \cite{Wohlin}. The creators of \ac{PAM}, \ac{TAA} and \ac{OPS} have already tried to mitigate this when creating their tools. Yet, there are still some aspects of internal validity, such as selection bias maturation and learning effect. As far as maturation is concerned, this comes to fatigue and boredom on the responses given by the teams. Although the surveys were small in size and did not require more than 15-20 minutes each, still the similar and possibly repetitive questions on the topic could cause tiredness and boredom to the subjects resulting in giving random answers to the survey questions. The mitigation for this threat was to separate the surveys in three different weeks. In addition, the respondents could stop the survey at any point and continue whenever they wanted. As far as the learning effect is concerned, this threat could not be mitigated. The learning effect threat applies in pre-post design studies only, but due to the same topic of the surveys, the subjects were to some extent more aware of what questions to expect in the second and third surveys. Finally, selection could not be mitigated as well since the case study focused on a specific company only.

%ask Lucas.
% This is not a pre-post design, but on the other hand, since there were surveys every week people might become more aware of agile practices during that period. Does this mean I had a testing threat?

%Testing Threat
%This threat only occurs in the pre-post design. What if taking the pretest made some of the children more aware of that kind of math problem -- it "primed" them for the program so that when you began the math training they were ready for it in a way that they wouldn't have been without the pretest. This is what is meant by a testing threat -- taking the pretest (not getting your program) affects how participants do on the posttest.

%Testing effects are not a problem in all studies. For example, as a "general rule of thumb", testing effects are less likely to be a threat to internal validity where there has been a large time period between the pre-test and post-test compared with experiments having a short interval between tests. You need to ask yourself: To what extent are learning effects a problem for the post-test in my experiment?

%http://dissertation.laerd.com/internal-validity-p3.php

\subsection{Conclusion Validity}
Conclusion validity concerns the possibility of reaching a wrong conclusion \cite{Wohlin}. Although the questions of the surveys have been carefully phrased by their creators, still there may be uncertainty about them. In order to mitigate this, for each survey a pilot one was conducted to spot any questions which would be difficult to understand. In addition, the participants could ask the author of this Master's Thesis for any questions they had concerning the survey questions. Finally the statistical tests were run only to the data that satisfied the prerequisites, to mitigate the possibility of incorrect results. %Violated assumptions of the test statistics

\subsection{External Validity}
External validity deals with the ability to generalize the outcomes of the case study \cite{Wohlin}. This Master's Thesis was conducted in collaboration with one company and 30 subjects only. Consequently, it is hard for the outcomes to be generalisable. Nevertheless, we believe that any researcher replicating the case study in another organization with teams which follow the same agile practices as those used in company A and identified in Table~\ref{table:methodologyA_practices} should have similar results.

\subsection{Reliability}
Reliability validity concerns on the dependence of the data and the analysis on the specific researchers \cite{Wohlin}. To provide the ability to other researchers to conduct a similar study, the steps followed have been described and the reasons for the decisions made have been explained. Furthermore, all the data exist in digital format which can be provided to anyone who wants to review them. %The presentation of the findings could be probably threatened by the author's experience. In order to mitigate this the findings were discussed with a company A employee who did not participate in the case study.


%Cronbach's alpha
%https://statistics.laerd.com/spss-tutorials/cronbachs-alpha-using-spss-statistics.php
%http://www.statisticshell.com/docs/reliability.pdf
%https://statistics.laerd.com/minitab-tutorials/cronbachs-alpha-using-minitab.php


%http://www.indiana.edu/~educy520/sec5982/week_9/520in_ex_validity.pdf
%http://en.wikipedia.org/wiki/Validity_%28statistics%29

%Internal
%Selection

%=====
%External
%Population

%===
%Construct
%Convergent - http://en.wikipedia.org/wiki/Convergent_validity

%===
%Criterion?
%Concurrent? - http://en.wikipedia.org/wiki/Concurrent_validity

%===
%Content?





%maybe use Cronbach alpha for validating the 3rd question (completness)