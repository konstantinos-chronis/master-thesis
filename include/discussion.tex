%discussion about the agility of the teams based on how they manage things
%discussion about the tools being close to the agile manifesto
%Dave Thomas argues about selling agility while we move away from agility (ruby grooves podcast - lister after 20th minute)
%http://msdn.microsoft.com/en-us/library/dd997578.aspx
%describe why it is difficult to measure. Companies adjust the methods to their needs. This is good, but the custom solutions are not measurable always Search for difficulties in agile or transitioning to agile. Difficulties in transition make people not adopting well the method and the practices.

\chapter{Discussion}
\label{ch:discussion}
%This chapter tried to check the correlations between \textit{Perceptive Agile Measurement}, \textit{Team Agility Assessment} and \textit{Objectives Practices and Strategies} tools. One would expect that their results would be similar, since their creators claim they can measure the agility of software development teams. Unfortunately, as it was seen in the analysis, the correlations among them were only few and most of them were very low (check subsection ~\ref{subsec:correlation_analysis}).

%\section{Unkwown}
%
%The agile philosophy became widely known to the Software Engineering community through the agile manifesto \cite{beck2001agile} which was also listed in the Introduction of this document. Along with the four pillars of the manifesto lie 12 principles \cite{agile_principles} which try to provide to people a better understanding of what agile means. All of them combined, consist the essence of what it is to be Agile \cite{agile_alliance}.
%
%\begin{itemize}
%	\item Our highest priority is to satisfy the customer through early and continuous delivery of valuable software.
%    \item Welcome changing requirements, even late in development. Agile processes harness change for the customer's competitive advantage.
%    \item Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale.
%    \item Business people and developers must work together daily throughout the project.
%    \item Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done.
%    \item The most efficient and effective method of conveying information to and within a development team is face-to-face conversation.
%    \item Working software is the primary measure of progress.
%    \item Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely.
%    \item Continuous attention to technical excellence and good design enhances agility.
%    \item Simplicity--the art of maximizing the amount of work not done--is essential.
%    \item The best architectures, requirements, and designs emerge from self-organizing teams.
%    \item At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behaviour accordingly.
%\end{itemize}
%
%Considering that the agile manifesto and its principles are the meaning of agility, then how well do the tools measuring agility succeed in doing so based on them?


\section{Threats to Validity}

\subsection{Construct Validity}
Construct validity mainly deals with obtaining the right method for the concept under study \cite{Wohlin}.

Structural?
Convergent validity?

%Here, mono-method bias was considered as a potential risk, and we tried
%to minimize by conducting pilot survey and interviews. The tools used to deploy our questionnaire guarantees subjects anonymity, thus helped us to avoid evaluation apprehension
%
%To assure a common understanding of the concepts used in data collection instruments, each study participant went through a printed survey form together with the researchers, where the latter explained every section in detail and the former was able to ask clarifying questions
%
%To alleviate the surveyâ€™s potential instrumentation flaws it was designed with the results of previous studies by Sekitoleko et al. [62] and Borjesson [9] and feedback of trial participants as an input.
%
%The evaluation apprehension threat [77], stemming from people being afraid of eval-
%uation by their nature, was mitigated by guaranteeing anonymity to every study partic-
%ipant within the company and in any publications of the study.
%
%Hypothesis Guessing
%
%http://www.socialresearchmethods.net/kb/constval.php


\subsection{Internal Validity}
Internal validity deals with the issues that may affect the casual relationship between treatment and results \cite{Wohlin}. The creators of \ac{PAM}, \ac{TAA} and \ac{OPS} have already tried to mitigate this when creating their tools. Yet, there are still some aspects of internal validity, such as selection bias and maturation. As far as maturation is concerned, this comes to boredom on the responses given by the teams. Although the surveys were small in size and did not require more than 15-20 minutes each, still the possibly repetitive questions on the topic could cause boredom to the subjects. The mitigation for this threat was to separate the surveys in three different weeks. In addition, the respondents could stop the survey at any point and continue whenever they wanted. Finally, selection could not be mitigated as a threat since the case study focused on a specific company.

\subsection{Conclusion Validity}
Conclusion validity concerns the possibility of reaching a wrong conclusion \cite{Wohlin}. Although the questions of the surveys have been carefully created, still there may be uncertainty about them. In order to mitigate this, for each survey a pilot one was conducted to spot any questions which would be difficult to understand. In addition, the participants could ask the author of this Master's Thesis for any questions they had concerning the survey questions.

\subsection{External Validity}
External validity deals with the ability to generalize the outcomes of the case study \cite{Wohlin}. Every software development team, even in the same company, applies agile methodologies in different ways. Nevertheless, the correlations among the tools are not context-specific and should not differ a lot due to the reasons explained in section~\ref{sec:findings}. Yet, as it is known, conducting a case study is susceptible to generalizing its outcomes. In this case though, we can consider that teams following the same agile practices should not have different results.

%\subsection{Reliability}
%Reliability validity concerns on the dependence of the data and the analysis on the specific researchers \cite{Wohlin}. To provide the ability to other researchers to conduct a similar study, the steps followed have been described and the reasons for the decisions made have been explained. All the data exist in digital format which can be provided to anyone who wants to review them. The presentation of the findings could be probably threatened by the author's experience. In order to mitigate this the findings were discussed with a company A employee who did not participate in the case study.



%http://www.indiana.edu/~educy520/sec5982/week_9/520in_ex_validity.pdf
%http://en.wikipedia.org/wiki/Validity_%28statistics%29

%Internal
%Selection

%=====
%External
%Population

%===
%Construct
%Convergent - http://en.wikipedia.org/wiki/Convergent_validity

%===
%Criterion?
%Concurrent? - http://en.wikipedia.org/wiki/Concurrent_validity

%===
%Content?





%maybe use Cronbach alpha for validating the 3rd question (completness)